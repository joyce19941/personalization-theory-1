{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from random import *\n",
    "import math\n",
    "#avg_ratings = pd.read_csv('/Users/Joyce/Desktop/Personalization Theory/project/Yelp/average_ratings.csv',index_col=0)\n",
    "original_data=pd.read_csv('/Users/Joyce/Desktop/Personalization Theory/project/Yelp/rating data 135.csv',index_col=0)\n",
    "#original_data=pd.read_csv('/Users/Joyce/Desktop/Personalization Theory/project/Yelp/rating data 125.csv',index_col=0)\n",
    "#original_data=pd.read_csv('/Users/Joyce/Desktop/Personalization Theory/project/Yelp/rating data 115.csv',index_col=0)\n",
    "#original_data=pd.read_csv('/Users/Joyce/Desktop/Personalization Theory/project/Yelp/rating data 105.csv',index_col=0)\n",
    "#original_data=pd.read_csv('/Users/Joyce/Desktop/Personalization Theory/project/Yelp/rating data 95.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split non-empty pairs data into 80% train and 20% test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "test=[]\n",
    "tune=[]\n",
    "train=[]\n",
    "random.seed(10)\n",
    "for j in original_data.columns:\n",
    "    for i in original_data.index:\n",
    "        r=random.random()\n",
    "        if not pd.isnull(original_data[j][i]):\n",
    "            if r<=0.6:\n",
    "                train.append([j,i,original_data[j][i]])\n",
    "            elif r>0.6 and r<=0.8:\n",
    "                tune.append([j,i,original_data[j][i]])\n",
    "            else:\n",
    "                test.append([j,i,original_data[j][i]])\n",
    "data_train=original_data.copy()\n",
    "for item in tune:\n",
    "    if item[0] in data_train.columns and item[1] in data_train.index:\n",
    "        data_train[item[0]][item[1]]=np.nan\n",
    "for item in test:\n",
    "    if item[0] in data_train.columns and item[1] in data_train.index:\n",
    "        data_train[item[0]][item[1]]=np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate similarity matrix of restaurants in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Step 1: calculate the mean centered rating matrix from the original dataset\n",
    "mean_ratings=data_train.mean(axis=0,skipna=True)\n",
    "substracted_data=data_train.copy()\n",
    "for j in substracted_data.columns:\n",
    "    for i in substracted_data.index:\n",
    "        if not pd.isnull(substracted_data[j][i]):\n",
    "            substracted_data[j][i]=substracted_data[j][i]-mean_ratings[j]\n",
    "#Step 2: function to compute similarity of any pair of 2 restaurantes\n",
    "def adjusted_cosine(u, v):\n",
    "    m = u.shape[0]\n",
    "    udotv = 0\n",
    "    u_norm = 0\n",
    "    v_norm = 0\n",
    "    for i in range(m):\n",
    "        if (np.isnan(u[i])) or (np.isnan(v[i])):\n",
    "            continue\n",
    "            \n",
    "        udotv += u[i] * v[i]\n",
    "        u_norm += u[i] * u[i]\n",
    "        v_norm += v[i] * v[i]\n",
    "        \n",
    "    u_norm = np.sqrt(u_norm)\n",
    "    v_norm = np.sqrt(v_norm)\n",
    "    \n",
    "    if (u_norm == 0) or (v_norm == 0):\n",
    "        ratio = 1.0\n",
    "    else:\n",
    "        ratio = udotv / (u_norm * v_norm)\n",
    "    return ratio\n",
    "#Step 3: create the similarity matrix\n",
    "items=substracted_data.columns\n",
    "similarity=pd.DataFrame(index=items, columns=items)\n",
    "for i in range(len(items)):\n",
    "    for j in range(len(items)):\n",
    "        similarity.ix[i][j] = adjusted_cosine(substracted_data.ix[:,i],substracted_data.ix[:,j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "item-based model with neighborhood size=t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def item_based(dataset,similarity,t):\n",
    "    data=dataset.copy()\n",
    "    for u in range(len(data.index)):\n",
    "        #get list of rated restaurent and its rating and unrated restaurants\n",
    "        rated_restaurants={}\n",
    "        unrated_id=[]\n",
    "        for i in range(len(data.ix[u])):\n",
    "            id_r=data.iloc[u].index[i]\n",
    "            if not pd.isnull(data.ix[u][i]):\n",
    "                if id_r not in rated_restaurants:\n",
    "                    rated_restaurants[id_r]=data.ix[u][i]\n",
    "            if pd.isnull(data.ix[u][i]):\n",
    "                    unrated_id.append(id_r)\n",
    "\n",
    "        #fill predicted ratings for unrated restaurents based on similarity and rating of rated restaurants\n",
    "        unrated_restaurants={}\n",
    "        unrated_restaurants=unrated_restaurants.fromkeys(unrated_id, None)\n",
    "        for k in unrated_restaurants:\n",
    "            neighbors={}\n",
    "            for j in rated_restaurants:\n",
    "                if similarity[k][j]>=0:\n",
    "                    if j not in neighbors:\n",
    "                        neighbors[j]=similarity[k][j]\n",
    "            neighbors=sorted(neighbors.items(),key=itemgetter(1),reverse=True)\n",
    "            nominator=0\n",
    "            denominator=0\n",
    "            #if no neighbour,just use the average rating of the restaurant by other users from the dataset\n",
    "            if len(neighbors)==0: \n",
    "                unrated_restaurants[k]=mean_ratings[k]\n",
    "            elif 0<len(neighbors)& len(neighbors)<t:\n",
    "                for n in neighbors:\n",
    "                    nominator+=n[1]*rated_restaurants[n[0]]\n",
    "                    denominator+=abs(n[1])\n",
    "                    #add a very small random number for recommendation selection in case many restaurants will have the same rating\n",
    "                    unrated_restaurants[k]=nominator/denominator+random()/100000\n",
    "            else:\n",
    "                for n in neighbors[:t]:\n",
    "                    nominator+=n[1]*rated_restaurants[n[0]]\n",
    "                    denominator+=abs(n[1])\n",
    "                    unrated_restaurants[k]=nominator/denominator\n",
    "\n",
    "        #fill in unrated restaurents ratings\n",
    "        for i in range(len(data.ix[u])):\n",
    "            if pd.isnull(data.ix[u][i]):\n",
    "                data.ix[u][i]=unrated_restaurants[''.join(data.ix[u,i:i+1].index.tolist())]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for neighborhood size from 1 to 20, calculate and compare the RMSE for each model to select the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import *\n",
    "rmse_list=[]\n",
    "for t in range(1,21):\n",
    "    prediction_train=item_based(dataset=data_train,similarity=similarity,t=t)\n",
    "    SUM=0\n",
    "    COUNT=0\n",
    "    for item in tune:\n",
    "        if item[0] in prediction_train.columns and item[1] in prediction_train.index:\n",
    "            SUM+=(prediction_train[item[0]][item[1]]-item[2])**2\n",
    "            COUNT+=1\n",
    "    RMSE=math.sqrt(SUM/COUNT)\n",
    "    rmse_list.append([t,RMSE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rmse_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-10793312065e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrmse_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'rmse_list' is not defined"
     ]
    }
   ],
   "source": [
    "rmse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmse_list=[\n",
    " [1, 1.3071464370353465],\n",
    " [2, 1.2126399065206135],\n",
    " [3, 1.184821847350271],\n",
    " [4, 1.17615928536058],\n",
    " [5, 1.1703095535923995],\n",
    " [6, 1.1671322967069724],\n",
    " [7, 1.1661703221368462],\n",
    " [8, 1.1660491128683121],\n",
    " [9, 1.1657912761767009],\n",
    " [10, 1.1657348748057679],\n",
    " [11, 1.1657992576527165],\n",
    " [12, 1.165769982276961],\n",
    " [13, 1.1657770431928116],\n",
    " [14, 1.1656986794703161],\n",
    " [15, 1.1657180030316867],\n",
    " [16, 1.1657127691870086],\n",
    " [17, 1.1656567683132888],\n",
    " [18, 1.1656319921815093],\n",
    " [19, 1.1656324072669737],\n",
    " [20, 1.1656275549944415]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "plot_data = np.array(rmse_list)\n",
    "x, y = plot_data.T\n",
    "plt.plot(x,y)\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel('Neighorhood Size')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()\n",
    "plt.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE varies little when we increase neighborhood size from 10 to 20.\n",
    "Therefore, we choose neighborhood size t=10 to be the best neighborhood size to avoid overfitting\n",
    "calculate rmse on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculate rmse on the test dataset\n",
    "from random import *\n",
    "prediction_train=item_based(dataset=data_train,similarity=similarity,t=10)\n",
    "SUM=0\n",
    "COUNT=0\n",
    "for item in test:\n",
    "    if item[0] in prediction_train.columns and item[1] in prediction_train.index:\n",
    "        if not pd.isnull(prediction_train[item[0]][item[1]]):\n",
    "            SUM+=(prediction_train[item[0]][item[1]]-item[2])**2\n",
    "            COUNT+=1\n",
    "test_RMSE=math.sqrt(SUM/COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coverage of the model:\n",
    "Calculate and compare RMSE when increasing the size of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_RMSE135=test_RMSE\n",
    "#test_RMSE125=test_RMSE\n",
    "#test_RMSE115=test_RMSE\n",
    "#test_RMSE105=test_RMSE\n",
    "#test_RMSE95=test_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.2069856768804772,\n",
       " 1.1858021424127776,\n",
       " 1.1919861843762687,\n",
       " 1.1650238390666052,\n",
       " 1.1686472176226619)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_RMSE135,test_RMSE125,test_RMSE115,test_RMSE105,test_RMSE95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.close>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverage_RMSEs=[1.2069856768804772, 1.1858021424127776, 1.1919861843762687,1.1650238390666052,1.1686472176226619]\n",
    "#test_RMSE135,test_RMSE125,test_RMSE115,test_RMSE105,test_RMSE95 dataset size\n",
    "coverage_size=[387300, 498491, 595620, 722455, 848598]\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(coverage_size,coverage_RMSEs)\n",
    "plt.scatter(coverage_size,coverage_RMSEs)\n",
    "plt.xlabel('Dataset Size')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()\n",
    "plt.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
